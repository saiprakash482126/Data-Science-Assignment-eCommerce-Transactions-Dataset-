{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI4sdFaehnhY",
        "outputId": "62c8c9ca-3a7f-40c1-84d5-5a4ef3f630bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lookalike.csv has been created!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import json\n",
        "\n",
        "# Function to load datasets safely\n",
        "def load_data(file_name):\n",
        "    try:\n",
        "        return pd.read_csv(file_name)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file {file_name} was not found.\")\n",
        "        return None\n",
        "\n",
        "# Load the datasets\n",
        "customers = load_data(\"Customers.csv\")\n",
        "products = load_data(\"Products.csv\")\n",
        "transactions = load_data(\"Transactions.csv\")\n",
        "\n",
        "# Check if data loaded successfully\n",
        "if customers is not None and products is not None and transactions is not None:\n",
        "    # Convert date columns to datetime\n",
        "    customers['SignupDate'] = pd.to_datetime(customers['SignupDate'])\n",
        "    transactions['TransactionDate'] = pd.to_datetime(transactions['TransactionDate'])\n",
        "\n",
        "    # Extract year and month features for analysis\n",
        "    customers['SignupYear'] = customers['SignupDate'].dt.year\n",
        "    transactions['TransactionMonth'] = transactions['TransactionDate'].dt.month\n",
        "    transactions['YearMonth'] = transactions['TransactionDate'].dt.to_period('M')\n",
        "\n",
        "    # Merge datasets to combine transaction, product, and customer information\n",
        "    transactions = transactions.merge(products, on=\"ProductID\", how=\"left\")\n",
        "    transactions = transactions.merge(customers, on=\"CustomerID\", how=\"left\")\n",
        "\n",
        "    # Aggregate features for each customer\n",
        "    customer_features = transactions.groupby(\"CustomerID\").agg(\n",
        "        total_spending=(\"TotalValue\", \"sum\"),\n",
        "        total_transactions=(\"TransactionID\", \"count\"),\n",
        "        avg_quantity=(\"Quantity\", \"mean\"),\n",
        "        favorite_category=(\"Category\", lambda x: x.mode()[0] if len(x.mode()) > 0 else \"Unknown\"),\n",
        "    ).reset_index()\n",
        "\n",
        "    # One-hot encode the favorite category\n",
        "    customer_features = pd.get_dummies(customer_features, columns=[\"favorite_category\"], prefix=\"cat\")\n",
        "\n",
        "    # Merge back with demographic data\n",
        "    customer_features = customer_features.merge(\n",
        "        customers[[\"CustomerID\", \"Region\", \"SignupYear\"]], on=\"CustomerID\", how=\"left\"\n",
        "    )\n",
        "\n",
        "    # One-hot encode the Region column\n",
        "    customer_features = pd.get_dummies(customer_features, columns=[\"Region\"], prefix=\"region\")\n",
        "\n",
        "    # Standardize numeric features\n",
        "    scaler = StandardScaler()\n",
        "    numeric_features = [\"total_spending\", \"total_transactions\", \"avg_quantity\", \"SignupYear\"]\n",
        "    customer_features[numeric_features] = scaler.fit_transform(customer_features[numeric_features])\n",
        "\n",
        "    # Compute pairwise similarity using cosine similarity\n",
        "    feature_matrix = customer_features.drop(columns=[\"CustomerID\"]).values\n",
        "    similarity_matrix = cosine_similarity(feature_matrix)\n",
        "\n",
        "    # Get top 3 similar customers for each customer\n",
        "    lookalikes = {}\n",
        "    customer_ids = customer_features[\"CustomerID\"].tolist()\n",
        "\n",
        "    for idx, customer_id in enumerate(customer_ids):\n",
        "        # Get similarity scores for the current customer\n",
        "        similarities = list(enumerate(similarity_matrix[idx]))\n",
        "        # Exclude the current customer and sort by similarity score\n",
        "        similarities = sorted([s for s in similarities if s[0] != idx], key=lambda x: x[1], reverse=True)[:3]\n",
        "        # Map to customer IDs and scores\n",
        "        lookalikes[customer_id] = [(customer_ids[i], round(score, 4)) for i, score in similarities]\n",
        "\n",
        "    # Create a DataFrame for the first 20 customers\n",
        "    lookalike_df = pd.DataFrame({\n",
        "        \"cust_id\": list(lookalikes.keys())[:20],\n",
        "        \"lookalikes\": [\n",
        "            json.dumps([{\"cust_id\": cust_id, \"score\": round(score, 4)} for cust_id, score in lookalikes[cust_id]])\n",
        "            for cust_id in list(lookalikes.keys())[:20]\n",
        "        ],\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    lookalike_df.to_csv(\"Lookalike.csv\", index=False)\n",
        "\n",
        "    print(\"Lookalike.csv has been created!\")\n",
        "else:\n",
        "    print(\"Data loading was unsuccessful. Please check the file paths.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1_0VhJIbh2nB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}